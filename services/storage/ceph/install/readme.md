## üóÑÔ∏è Rook-Ceph - –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è Kubernetes

> **Rook-Ceph** ‚Äî —ç—Ç–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è Ceph –∫–ª–∞—Å—Ç–µ—Ä–∞ –≤ Kubernetes. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–ª–æ—á–Ω—ã–µ (RBD), —Ñ–∞–π–ª–æ–≤—ã–µ (CephFS) –∏ –æ–±—ä–µ–∫—Ç–Ω—ã–µ (RGW) —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.

## üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Å–∫–æ–≤ –Ω–∞ VPS

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Å–∫–∞ –∏ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ:

```bash
# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–∑–¥–µ–ª—ã –∏ —Å–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ
sudo parted -s /dev/sda unit GiB print free

# –ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ä–µ–≤–æ –¥–∏—Å–∫–æ–≤
lsblk -o NAME,SIZE,TYPE,FSTYPE,MOUNTPOINT
```

### –í–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤

#### 1. LVM loop mount

```bash
# –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª 10GB (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–æ–±–æ–¥–Ω—ã–µ 17GB)
# fallocate –±—ã—Å—Ç—Ä–æ –≤—ã–¥–µ–ª—è–µ—Ç –º–µ—Å—Ç–æ –±–µ–∑ –∑–∞–ø–∏—Å–∏ –Ω—É–ª–µ–π
fallocate -l 10G /ceph-disk.img

# –ü—Ä–æ–≤–µ—Ä—è–µ–º
ls -lh /ceph-disk.img
```

```bash
# –°–æ–∑–¥–∞—ë–º loop device –∏–∑ —Ñ–∞–π–ª–∞
losetup -f /ceph-disk.img

# –£–∑–Ω–∞—ë–º –∫–∞–∫–æ–π loop device –Ω–∞–∑–Ω–∞—á–µ–Ω
losetup -a | grep ceph-disk

# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ-—Ç–æ —Ç–∏–ø–∞: /dev/loop0: []:12345 (/ceph-disk.img)
```

```bash
# –°–æ–∑–¥–∞—ë–º LVM (–∑–∞–º–µ–Ω–∏—Ç–µ loop0 –Ω–∞ –≤–∞—à –Ω–æ–º–µ—Ä)
pvcreate /dev/loop0
vgcreate ceph-vg-1 /dev/loop0
lvcreate -l 100%FREE -n osd-lv ceph-vg-1

# –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
# –ü—Ä–æ–≤–µ—Ä—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
losetup -a
# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å: /dev/loop0: ... (/ceph-disk.img)

ceph-volume inventory /dev/ceph-vg-1/osd-lv
# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å: LV Status = available
```

–ê–≤—Ç–æ–∑–∞–ø—É—Å–∫ loop device –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ

```bash
cat > /etc/systemd/system/ceph-loop.service <<'EOF'
[Unit]
Description=Setup loop device for Ceph
DefaultDependencies=no
After=local-fs.target
Before=lvm2-activation-early.service

[Service]
Type=oneshot
ExecStart=/sbin/losetup /dev/loop0 /ceph-disk.img
RemainAfterExit=yes

[Install]
WantedBy=local-fs.target
EOF

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º
systemctl daemon-reload
systemctl enable ceph-loop.service
systemctl start ceph-loop.service
```

–í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Ceph –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LVM –ø—É—Ç—å:

```yaml
nodes:
  - name: control-worker-1
    devices:
      - name: /dev/ceph-vg-1/osd-lv # ‚Üê LVM –ø—É—Ç—å
```

#### 2. LVM root mount (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª)

```bash
# –ù–∞ –ö–ê–ñ–î–û–ô –Ω–æ–¥–µ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Ä–∞–∑–¥–µ–ª–æ–º –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

# –®–∞–≥ 1: –°–æ–∑–¥–∞—Ç—å —Ä–∞–∑–¥–µ–ª (–µ—Å–ª–∏ –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω)
sgdisk --new=4:0:0 --typecode=4:8300 --change-name=4:ceph-osd /dev/sda
partprobe /dev/sda

# –®–∞–≥ 2: –°–æ–∑–¥–∞—Ç—å Physical Volume
pvcreate /dev/sda4

# –®–∞–≥ 3: –°–æ–∑–¥–∞—Ç—å Volume Group (–∏–º—è –£–ù–ò–ö–ê–õ–¨–ù–û–ï –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–¥—ã!)
vgcreate ceph-vg-1 /dev/sda4  # –Ω–∞ –ø–µ—Ä–≤–æ–π –Ω–æ–¥–µ
# vgcreate ceph-vg-2 /dev/sda4  # –Ω–∞ –≤—Ç–æ—Ä–æ–π –Ω–æ–¥–µ
# vgcreate ceph-vg-3 /dev/sda4  # –Ω–∞ —Ç—Ä–µ—Ç—å–µ–π –Ω–æ–¥–µ

# –®–∞–≥ 4: –°–æ–∑–¥–∞—Ç—å Logical Volume –Ω–∞ –í–°–Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
lvcreate -l 100%FREE -n osd-lv ceph-vg-1

# –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
# –ü—Ä–æ–≤–µ—Ä—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
losetup -a
# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å: /dev/loop0: ... (/ceph-disk.img)

ceph-volume inventory /dev/ceph-vg-1/osd-lv
# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å: LV Status = available
```

–í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Ceph –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LVM –ø—É—Ç—å:

```yaml
nodes:
  - name: control-worker-1
    devices:
      - name: /dev/ceph-vg-1/osd-lv # ‚Üê LVM –ø—É—Ç—å
```

#### 3. Disk ID

```bash
# –ü–æ–∫–∞–∑–∞—Ç—å ID –¥–∏—Å–∫–æ–≤
ls -l /dev/disk/by-id/ | grep sda4


```

–¢–µ–ø–µ—Ä—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Ceph –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—É—Ç—å –∫ –¥–∏—Å–∫—É:

```yaml
nodes:
  - name: control-worker-1
    devices:
      - name: /dev/sda4 # ‚Üê ID Disk –ø—É—Ç—å (scsi-0QEMU_QEMU_HARDDISK_drive-scsi0-part4)
```

## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Helm (Lens UI)

> values-operator.yaml (–¥–ª—è rook-ceph)

```yaml
# === Rook-Ceph Operator (control plane) ===
image:
  repository: docker.io/rook/ceph
  tag: v1.18.4
  pullPolicy: IfNotPresent

# CRD —Å–æ–∑–¥–∞—ë–º –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º (–ø—Ä–∏ –ø–µ—Ä–≤–æ–º –¥–µ–ø–ª–æ–µ –æ—Å—Ç–∞–≤–∏—Ç—å true)
crds:
  enabled: true

# –†–µ—Å—É—Ä—Å—ã —Å–∞–º–æ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ (–µ–º—É –º–Ω–æ–≥–æ –Ω–µ –Ω—É–∂–Ω–æ)
resources:
  requests:
    cpu: 200m
    memory: 128Mi
  limits:
    memory: 512Mi

# –ì–¥–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –≤ –ª—é–±–æ–º —É–∑–ª–µ.
# currentNamespaceOnly=false –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø–µ—Ä–∞—Ç–æ—Ä—É –≤–∏–¥–µ—Ç—å CR –∏–∑ —Å–≤–æ–µ–≥–æ –Ω–µ–π–º—Å–ø–µ–π—Å–∞ (rook-ceph) –∏ —É–ø—Ä–∞–≤–ª—è—Ç—å –∏–º–∏.
currentNamespaceOnly: false

# –û–±—â–∏–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–æ–≤ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
logLevel: INFO

# RBAC –≤–∫–ª—é—á—ë–Ω
rbacEnable: true

# === CSI (Container Storage Interface) - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Ceph —Å Kubernetes ===
# CSI –¥—Ä–∞–π–≤–µ—Ä—ã –ø–æ–∑–≤–æ–ª—è—é—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å PVC (Persistent Volume Claims) –≤ K8s
csi:
  # rookUseCsiOperator - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π CSI –æ–ø–µ—Ä–∞—Ç–æ—Ä (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
  rookUseCsiOperator: true

  # === –¢–∏–ø—ã —Ö—Ä–∞–Ω–∏–ª–∏—â (–≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏) ===
  #
  # ‚ÑπÔ∏è –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ 2 –¥—Ä–∞–π–≤–µ—Ä–∞ - —ç—Ç–æ –ü–†–ê–í–ò–õ–¨–ù–û!
  # Object Storage (S3) –ù–ï —Ç—Ä–µ–±—É–µ—Ç CSI –¥—Ä–∞–π–≤–µ—Ä–∞, —Ç.–∫. —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ HTTP API
  # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Object Storage –≤ values-cluster.yaml (—Å–µ–∫—Ü–∏—è cephObjectStores)

  # RBD (Block Storage) - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞
  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –ë–î, stateful –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, PVC —Å —Ä–µ–∂–∏–º–æ–º ReadWriteOnce (RWO)
  # –ú–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ –±–ª–æ—á–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤ –ø–æ–¥
  enableRbdDriver: true

  # CephFS (File System) - –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û
  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: Shared storage, ReadWriteMany (RWX), –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥–æ–≤ –ø–∏—à—É—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
  # –ú–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤ –ø–æ–¥—ã
  # –í—ã–∫–ª—é—á–∏—Ç—å –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–µ–Ω: enableCephfsDriver: false
  enableCephfsDriver: false

  # –û–±—â–∏–π –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å CSI (–≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å "false" —á—Ç–æ–±—ã CSI —Ä–∞–±–æ—Ç–∞–ª)
  disableCsiDriver: "false"

  # ========================================================================
  # PROVISIONER - —É–ø—Ä–∞–≤–ª—è—é—â–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (—Å–æ–∑–¥–∞–µ—Ç/—É–¥–∞–ª—è–µ—Ç RBD –æ–±—Ä–∞–∑—ã)
  # ========================================================================
  # –≠—Ç–æ Deployment (–Ω–µ DaemonSet) - –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ storage-–Ω–æ–¥–∞—Ö

  # Tolerations - —Ä–∞–∑—Ä–µ—à–∞–µ—Ç –∑–∞–ø—É—Å–∫ –Ω–∞ –Ω–æ–¥–∞—Ö —Å taint "workload=ceph:NoSchedule"
  # Storage-–Ω–æ–¥—ã –∏–º–µ—é—Ç —ç—Ç–æ—Ç taint —á—Ç–æ–±—ã –æ–±—ã—á–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –Ω–∏—Ö –Ω–µ –ø–æ–ø–∞–ª–∏
  provisionerTolerations:
    - key: "workload" # –ö–ª—é—á taint –Ω–∞ storage-–Ω–æ–¥–∞—Ö
      operator: "Equal" # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
      value: "ceph" # –ó–Ω–∞—á–µ–Ω–∏–µ taint
      effect: "NoSchedule" # –¢–∏–ø —ç—Ñ—Ñ–µ–∫—Ç–∞

  # NodeAffinity - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∑–∞–ø—É—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ storage-–Ω–æ–¥–∞—Ö
  # Storage-–Ω–æ–¥—ã –ø–æ–º–µ—á–µ–Ω—ã label "node-role.kubernetes.io/storage=true"
  provisionerNodeAffinity: |
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: node-role.kubernetes.io/storage
              operator: In
              values: ["true"]

  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–ª–∏–∫ Provisioner –¥–ª—è High Availability (HA)
  # 2 —Ä–µ–ø–ª–∏–∫–∏ = –µ—Å–ª–∏ –æ–¥–Ω–∞ storage-–Ω–æ–¥–∞ —É–ø–∞–¥–µ—Ç, –≤—Ç–æ—Ä–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É
  provisionerReplicas: 2

  # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Ä–∞–∑–Ω–µ—Å—Ç–∏ —Ä–µ–ø–ª–∏–∫–∏ –ø–æ —Ä–∞–∑–Ω—ã–º –Ω–æ–¥–∞–º:
  # –ù–∞—á–∏–Ω–∞—è —Å –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π Rook/CSI —ç—Ç–æ –∑–∞–¥–∞—ë—Ç—Å—è —á–µ—Ä–µ–∑ podAntiAffinity —É —Å–∞–º–æ–≥–æ —á–∞—Ä—Ç–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ.
  # –ü—Ä–æ—â–µ: –ø–æ–º–µ—Ç—å storage-–Ω–æ–¥—ã —Ä–∞–∑–Ω—ã–º–∏ –∑–æ–Ω–∞–º–∏/labels –∏ –¥–æ–±–∞–≤—å topologySpreadConstraints –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–ª–∞—Å—Ç–µ—Ä–∞.

  # ========================================================================
  # NODEPLUGIN - –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∏—Å–∫–æ–≤ –Ω–∞ –Ω–æ–¥–∞—Ö
  # ========================================================================
  # –≠—Ç–æ DaemonSet - –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –ö–ê–ñ–î–û–ô –Ω–æ–¥–µ –≥–¥–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è PVC
  #
  # ‚ö†Ô∏è –í–ê–ñ–ù–û: NodePlugin –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ç–æ–π –Ω–æ–¥–µ, –≥–¥–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ–¥ —Å PVC!
  #   - –ï—Å–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ worker-–Ω–æ–¥–µ ‚Üí nodeplugin –Ω—É–∂–µ–Ω –Ω–∞ worker-–Ω–æ–¥–µ
  #   - –ï—Å–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ storage-–Ω–æ–¥–µ ‚Üí nodeplugin –Ω—É–∂–µ–Ω –Ω–∞ storage-–Ω–æ–¥–µ
  #   - Masters –æ–±—ã—á–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω—ã (–Ω–∞ –Ω–∏—Ö –Ω–µ –∑–∞–ø—É—Å–∫–∞—é—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)

  # Tolerations - —Ä–∞–∑—Ä–µ—à–∞–µ—Ç –∑–∞–ø—É—Å–∫ –Ω–∞ storage-–Ω–æ–¥–∞—Ö (–≥–¥–µ taint workload=ceph)
  pluginTolerations:
    - key: "workload" # –ö–ª—é—á taint
      operator: "Equal" # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
      value: "ceph" # –ó–Ω–∞—á–µ–Ω–∏–µ taint
      effect: "NoSchedule" # –¢–∏–ø —ç—Ñ—Ñ–µ–∫—Ç–∞

  # pluginNodeAffinity –ù–ï –∑–∞–¥–∞—ë–º - nodeplugin –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –Ω–∞ –≤—Å–µ—Ö –Ω–æ–¥–∞—Ö
  # Masters –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (—É –Ω–∏—Ö taint control-plane –±–µ–∑ toleration)
  # –†–µ–∑—É–ª—å—Ç–∞—Ç: nodeplugin –Ω–∞ –≤—Å–µ—Ö worker + storage –Ω–æ–¥–∞—Ö
  #
  # ‚ö†Ô∏è –í–ê–ñ–ù–û: –ù–ï –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ storage-–Ω–æ–¥–∞–º–∏!
  # –ï—Å–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ - –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ worker-–Ω–æ–¥–∞—Ö –Ω–µ —Å–º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PVC
  #
  # –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –Ø–í–ù–û –∏—Å–∫–ª—é—á–∏—Ç—å masters (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ), —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ:
  # pluginNodeAffinity: |
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #       - matchExpressions:
  #           - key: node-role.kubernetes.io/control-plane
  #             operator: DoesNotExist

  # HostNetwork –¥–ª—è CSI-–ø–ª–∞–≥–∏–Ω–æ–≤ ‚Äî –ø–æ–ª–µ–∑–Ω–æ –≤ –ø—Ä–æ—Å—Ç—ã—Ö/–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö.
  enableCSIHostNetwork: true

  # –í–∫–ª—é—á–∞–µ–º —Å–Ω–∞–ø—à–æ—Ç—Ç–µ—Ä—ã (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ —É–¥–æ–±–Ω–æ)
  enableRBDSnapshotter: true
  enableCephfsSnapshotter: false

  # –ü–æ–ª–∏—Ç–∏–∫–∞ —Å–º–µ–Ω—ã –≤–ª–∞–¥–µ–ª—å—Ü–∞/–ø—Ä–∞–≤ –ø—Ä–∏ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ç–æ–º–∞
  rbdFSGroupPolicy: "File"
  cephFSFSGroupPolicy: "File"

  # ========================================================================
  # –†–ï–°–£–†–°–´ (Requests/Limits) - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –Ω–æ–¥ —Å 4GB RAM
  # ========================================================================
  # Requests - —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏–µ (K8s –Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç)
  # Limits - –º–∞–∫—Å–∏–º—É–º (–ø–æ–¥ –±—É–¥–µ—Ç killed –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—Å–∏—Ç)

  # --- RBD Provisioner (Deployment –Ω–∞ storage-–Ω–æ–¥–∞—Ö) ---
  # –°–æ–∑–¥–∞–µ—Ç/—É–¥–∞–ª—è–µ—Ç RBD –æ–±—Ä–∞–∑—ã –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º PVC
  csiRBDProvisionerResource: |
    - name : csi-provisioner      # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç provisioning
      resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
    - name : csi-resizer          # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ç–æ–º–æ–≤ (volume expansion)
      resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
    - name : csi-attacher         # Attach/Detach —Ç–æ–º–æ–≤ –∫ –Ω–æ–¥–∞–º
      resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
    - name : csi-snapshotter      # –°–æ–∑–¥–∞–Ω–∏–µ —Å–Ω–∞–ø—à–æ—Ç–æ–≤
      resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
    - name : csi-rbdplugin        # RBD –¥—Ä–∞–π–≤–µ—Ä
      resource: { requests: { memory: 384Mi }, limits: { memory: 768Mi } }
    - name : liveness-prometheus  # Health checks + –º–µ—Ç—Ä–∏–∫–∏
      resource: { requests: { memory: 64Mi, cpu: 25m }, limits: { memory: 128Mi } }

  # --- RBD NodePlugin (DaemonSet –Ω–∞ –≤—Å–µ—Ö worker/storage –Ω–æ–¥–∞—Ö) ---
  # –ú–æ–Ω—Ç–∏—Ä—É–µ—Ç RBD –¥–∏—Å–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ –Ω–æ–¥–µ –¥–ª—è –ø–æ–¥–æ–≤
  # –í–ê–ñ–ù–û: –£–º–µ–Ω—å—à–µ–Ω—ã requests —á—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –¥–∞–∂–µ –Ω–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–æ–¥–∞—Ö
  csiRBDPluginResource: |
    - name : driver-registrar     # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ –≤ kubelet
      resource: { requests: { memory: 32Mi, cpu: 25m }, limits: { memory: 64Mi } }
    - name : csi-rbdplugin        # RBD –¥—Ä–∞–π–≤–µ—Ä –¥–ª—è –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
      resource: { requests: { memory: 256Mi, cpu: 100m }, limits: { memory: 512Mi } }
    - name : liveness-prometheus  # Health checks
      resource: { requests: { memory: 32Mi, cpu: 25m }, limits: { memory: 64Mi } }
  # –ò—Ç–æ–≥–æ –Ω–∞ –Ω–æ–¥—É: 320Mi requests (–±—ã–ª–æ 512Mi - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ!)

  # --- CephFS Provisioner (Deployment –Ω–∞ storage-–Ω–æ–¥–∞—Ö) ---
  # –°–æ–∑–¥–∞–µ—Ç/—É–¥–∞–ª—è–µ—Ç CephFS volumes (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ enableCephfsDriver: true)
  # csiCephFSProvisionerResource: |
  #   - name : csi-provisioner      # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç provisioning
  #     resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
  #   - name : csi-resizer          # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ç–æ–º–æ–≤
  #     resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
  #   - name : csi-attacher         # Attach/Detach —Ç–æ–º–æ–≤
  #     resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
  #   - name : csi-snapshotter      # –°–Ω–∞–ø—à–æ—Ç—ã CephFS
  #     resource: { requests: { memory: 128Mi, cpu: 100m }, limits: { memory: 256Mi } }
  #   - name : csi-cephfsplugin     # CephFS –¥—Ä–∞–π–≤–µ—Ä
  #     resource: { requests: { memory: 384Mi, cpu: 150m }, limits: { memory: 768Mi } }
  #   - name : liveness-prometheus  # Health checks
  #     resource: { requests: { memory: 64Mi, cpu: 25m }, limits: { memory: 128Mi } }

  # --- CephFS NodePlugin (DaemonSet –Ω–∞ –≤—Å–µ—Ö worker/storage –Ω–æ–¥–∞—Ö) ---
  # –ú–æ–Ω—Ç–∏—Ä—É–µ—Ç CephFS –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ –Ω–æ–¥–µ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ enableCephfsDriver: true)
  # csiCephFSPluginResource: |
  #   - name : driver-registrar     # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞
  #     resource: { requests: { memory: 32Mi, cpu: 25m }, limits: { memory: 64Mi } }
  #   - name : csi-cephfsplugin     # CephFS –¥—Ä–∞–π–≤–µ—Ä –¥–ª—è –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
  #     resource: { requests: { memory: 256Mi, cpu: 100m }, limits: { memory: 512Mi } }
  #   - name : liveness-prometheus  # Health checks
  #     resource: { requests: { memory: 32Mi, cpu: 25m }, limits: { memory: 64Mi } }
  # –ò—Ç–æ–≥–æ –Ω–∞ –Ω–æ–¥—É: 320Mi requests (–±—ã–ª–æ 512Mi - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ!)

# discoveryDaemon –≤—ã–∫–ª—é—á–µ–Ω ‚Äî –æ–Ω –∞–≤—Ç–æ-—Å–∫–∞–Ω–∏—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞. –ú—ã –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö —Ä—É–∫–∞–º–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–π —á–∞—Å—Ç–∏.
enableDiscoveryDaemon: false
# TODO: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–±—ã.
```

> values-cluster.yaml (–¥–ª—è rook-ceph-cluster)

```yaml
# === rook/rook-ceph-cluster values (–≥–æ—Ç–æ–≤–æ –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é) ===
operatorNamespace: rook-ceph

cephClusterSpec:
  dataDirHostPath: /var/lib/rook

  cephVersion:
    image: quay.io/ceph/ceph:v18.2.2 # Reef (—Ä–∞–±–æ—á–∏–π —Ç–µ–≥)

  dashboard:
    enabled: true
    ssl: true

  mon:
    count: 3
    allowMultiplePerNode: false

  mgr:
    count: 1
    allowMultiplePerNode: false
    # –Ø–≤–Ω–æ –≤–∫–ª—é—á–∞–µ–º –º–æ–¥—É–ª–∏ MGR (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Object Storage - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑–∞—Ç—å rgw)
    modules:
      - name: rgw # –î–ª—è Object Gateway –≤ Dashboard
        enabled: true

  # ========================================================================
  # PLACEMENT - –≥–¥–µ –∑–∞–ø—É—Å–∫–∞—Ç—å Ceph –¥–µ–º–æ–Ω—ã (MON/MGR/OSD)
  # ========================================================================
  # all - –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ –≤—Å–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º (mon, mgr, osd)
  placement:
    all:
      # Tolerations - —Ä–∞–∑—Ä–µ—à–∞–µ—Ç –∑–∞–ø—É—Å–∫ –Ω–∞ storage-–Ω–æ–¥–∞—Ö —Å taint
      tolerations:
        - key: "workload" # –ö–ª—é—á taint –Ω–∞ storage-–Ω–æ–¥–∞—Ö
          operator: "Equal"
          value: "ceph" # –ó–Ω–∞—á–µ–Ω–∏–µ taint
          effect: "NoSchedule" # –≠—Ñ—Ñ–µ–∫—Ç (NoSchedule = –æ–±—ã—á–Ω—ã–µ –ø–æ–¥—ã –Ω–µ –ø–æ–ø–∞–¥—É—Ç)

      # NodeAffinity - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ç–æ–ª—å–∫–æ –Ω–∞ storage-–Ω–æ–¥–∞—Ö
      # –î–µ–º–æ–Ω—ã Ceph –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω–æ–¥–∞—Ö —Å label storage=true
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: node-role.kubernetes.io/storage
                  operator: In
                  values: ["true"]

  # ========================================================================
  # –†–ï–°–£–†–°–´ –¥–ª—è Ceph –¥–µ–º–æ–Ω–æ–≤ - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ 4GB RAM –Ω–æ–¥—ã
  # ========================================================================
  # –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –†–ï–ê–õ–¨–ù–û–ú –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ –≤ production
  # Requests –∑–∞–Ω–∏–∂–µ–Ω—ã (—Ä–µ–∞–ª—å–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –≤—ã—à–µ) –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏—è
  resources:
    # MON (Monitor) - —Ö—Ä–∞–Ω–∏—Ç –∫–∞—Ä—Ç—É –∫–ª–∞—Å—Ç–µ—Ä–∞, –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è 3 —à—Ç –¥–ª—è –∫–≤–æ—Ä—É–º–∞ (quorum)
    mon:
      requests: { cpu: "150m", memory: "384Mi" } # —Ä–µ–∞–ª—å–Ω–æ ~460Mi
      limits: { memory: "1Gi" }

    # MGR (Manager) - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, Dashboard, –º–µ—Ç—Ä–∏–∫–∏
    # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è 1-2 —à—Ç (active + standby)
    mgr:
      requests: { cpu: "150m", memory: "512Mi" } # —Ä–µ–∞–ª—å–Ω–æ ~540Mi
      limits: { memory: "1Gi" }

    # OSD (Object Storage Daemon) - —Ö—Ä–∞–Ω–∏—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –¥–∏—Å–∫–∞—Ö
    # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ 1 –Ω–∞ –∫–∞–∂–¥—ã–π –¥–∏—Å–∫ (—É –≤–∞—Å 3 OSD)
    osd:
      requests: { cpu: "400m", memory: "512Mi" } # —Ä–µ–∞–ª—å–Ω–æ ~350Mi
      limits: { memory: "1.5Gi" }

  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ OSD
  annotations:
    osd:
      rook.io/ceph-osd-memory-target: "1073741824" # ~1GiB

  # –Ø–í–ù–û –∑–∞–¥–∞—ë–º –¥–∏—Å–∫–∏/—Ä–∞–∑–¥–µ–ª—ã (–Ω–∏–∫–∞–∫–æ–≥–æ useAll*)
  # –í–ê–ñ–ù–û: –î–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ (—á–µ—Ä–µ–∑ resize) –∏—Å–ø–æ–ª—å–∑—É–µ–º LVM!
  storage:
    useAllNodes: false
    useAllDevices: false
    nodes:
      - name: control-worker-7nfqwbbv
        devices:
          - name: /dev/ceph-vg-1/osd-lv # LVM –ø–æ–≤–µ—Ä—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
      - name: control-worker-sb9u8lc6
        devices:
          - name: /dev/ceph-vg-2/osd-lv # LVM –ø–æ–≤–µ—Ä—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
      - name: control-worker-qkzswwul
        devices:
          - name: /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_drive-scsi1 # –û—Ç–¥–µ–ª—å–Ω—ã–π –¥–∏—Å–∫

  # –ú–æ–∂–Ω–æ –≤—ã–∫–ª—é—á–∏—Ç—å —Å–±–æ—Ä—â–∏–∫ –∫—Ä—ç—à–µ–π –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö –Ω–æ–¥–∞—Ö
  crashCollector:
    disable: true

# --- –ü—É–ª RBD + StorageClass (RWO, –ø–æ–¥ –ë–î –∏ —Ç.–ø.) ---
cephBlockPools:
  - name: replicapool
    spec:
      failureDomain: host
      replicated:
        size: 2 # —Å—Ç–∞—Ä—Ç–æ–≤–æ —ç–∫–æ–Ω–æ–º–∏–º –º–µ—Å—Ç–æ; –ø–æ–∑–∂–µ –ø–µ—Ä–µ–≤–µ–¥—ë—à—å –Ω–∞ 3
    storageClass:
      enabled: true
      name: ceph-rbd
      isDefault: true # —Å–¥–µ–ª–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∫–ª–∞—Å—Å–æ–º
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      volumeBindingMode: WaitForFirstConsumer
      parameters:
        imageFormat: "2"
        imageFeatures: layering
        csi.storage.k8s.io/fstype: ext4
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
        csi.storage.k8s.io/controller-publish-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-publish-secret-namespace: "{{ .Release.Namespace }}"
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
        csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"

# ========================================================================
# –£–ü–†–ê–í–õ–ï–ù–ò–ï –¢–ò–ü–ê–ú–ò –•–†–ê–ù–ò–õ–ò–©
# ========================================================================

# === RBD (Block Storage) - –í–°–ï–ì–î–ê –í–ö–õ–Æ–ß–ï–ù ===
# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –≤—ã—à–µ –≤ cephBlockPools (replicapool)

# === CephFS (File System) - –í–ö–õ–Æ–ß–ò–¢–¨/–í–´–ö–õ–Æ–ß–ò–¢–¨ –ü–û –ù–ï–û–ë–•–û–î–ò–ú–û–°–¢–ò ===
# –ï—Å–ª–∏ –ù–ï –Ω—É–∂–µ–Ω shared storage (RWX) - –æ—Ç–∫–ª—é—á–∏—Ç–µ:
#   1. –í values-operator.yaml: enableCephfsDriver: false
#   2. –ó–¥–µ—Å—å: storageClass.enabled: false (–∏–ª–∏ —É–¥–∞–ª–∏—Ç–µ –≤–µ—Å—å –±–ª–æ–∫ cephFileSystems)
#
# –≠–∫–æ–Ω–æ–º–∏—è: -48 PG, -2 MDS –ø–æ–¥–∞, -80Mi –ø–∞–º—è—Ç–∏
# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω CephFS –∏ –≤ values-cluster.yaml –≤–∫–ª—é—á–∏—Ç—å enableCephfsDriver: true
# cephFileSystems:
#   - name: cephfs
#     spec:
#       metadataPool:
#         replicated: { size: 2 } # –ø–æ–∑–∂–µ –º–æ–∂–Ω–æ –Ω–∞ 3
#       dataPools:
#         - replicated: { size: 2 }
#       metadataServer:
#         activeCount: 1
#         activeStandby: true
#     storageClass:
#       enabled: false # –≤–∫–ª—é—á–∏ true, –∫–æ–≥–¥–∞ RWX –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è
#       name: cephfs
#       allowVolumeExpansion: true
#       reclaimPolicy: Delete
#       volumeBindingMode: WaitForFirstConsumer
#       parameters:
#         mounter: kernel
#         csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
#         csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
#         csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
#         csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
#         csi.storage.k8s.io/controller-publish-secret-name: rook-csi-cephfs-provisioner
#         csi.storage.k8s.io/controller-publish-secret-namespace: "{{ .Release.Namespace }}"
#         csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
#         csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"

# === Object Storage (S3/Swift API) - –í–ö–õ–Æ–ß–ò–¢–¨/–í–´–ö–õ–Æ–ß–ò–¢–¨ ===
# RGW (RADOS Gateway) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç S3-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API –¥–ª—è –æ–±—ä–µ–∫—Ç–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
#
# ‚ö†Ô∏è –í–ê–ñ–ù–û: –°–æ–∑–¥–∞–µ—Ç 11+ –ø—É–ª–æ–≤ –∏ ~200 PG! –ë–æ–ª—å—à–æ–π overhead!
#
# ‚ÑπÔ∏è CSI –î–†–ê–ô–í–ï–† –ù–ï –ù–£–ñ–ï–ù: RGW —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ HTTP/S3 API (–Ω–µ –º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ volume)
#
# üí° –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–ª—è –º–∞–ª—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: MinIO + PVC –Ω–∞ Ceph RBD
#    - –ü—Ä–æ—â–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ, –∫—Ä–∞—Å–∏–≤—ã–π UI
#    - –ù–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—à–Ω–∏–π —Å–ª–æ–π (MinIO ‚Üí RBD ‚Üí Ceph)
#
# üéØ –î–ª—è –≤—ã–¥–µ–ª–µ–Ω–Ω—ã—Ö storage –Ω–æ–¥: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Ceph RGW (–Ω–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ)
#    - RGW –ø–æ–¥—ã –∑–∞–ø—É—Å—Ç—è—Ç—Å—è –Ω–∞ storage –Ω–æ–¥–∞—Ö —Ä—è–¥–æ–º —Å OSD
#    - –ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ Ceph, –º–µ–Ω—å—à–µ overhead
#
# –ï—Å–ª–∏ –ù–ï –Ω—É–∂–µ–Ω S3 API - –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –≤–µ—Å—å –±–ª–æ–∫ cephObjectStores
# –≠–∫–æ–Ω–æ–º–∏—è: -200+ PG, -1 RGW –ø–æ–¥, -–º–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏
#
# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω Object Storage:
cephObjectStores:
  - name: ceph-objectstore
    spec:
      # Metadata Pool - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–æ–≤ (–∏–º–µ–Ω–∞, –≤–ª–∞–¥–µ–ª—å—Ü—ã)
      metadataPool:
        failureDomain: host
        replicated:
          size: 3 # 3 —Ä–µ–ø–ª–∏–∫–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

      # Data Pool - –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–æ–≤ (erasure coded –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞)
      dataPool:
        failureDomain: host
        erasureCoded:
          dataChunks: 2 # 2 —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
          codingChunks: 1 # 1 —á–∞—Å—Ç—å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        parameters:
          bulk: "true" # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤

      # Gateway - HTTP —Å–µ—Ä–≤–µ—Ä (S3 API endpoint)
      gateway:
        instances: 1 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ RGW –ø–æ–¥–æ–≤
        port: 80
        priorityClassName: system-cluster-critical

        # Placement - –∑–∞–ø—É—Å–∫–∞–µ–º RGW –Ω–∞ storage –Ω–æ–¥–∞—Ö (—Ä—è–¥–æ–º —Å OSD)
        placement:
          tolerations:
            - key: workload
              operator: Equal
              value: ceph
              effect: NoSchedule
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                    - key: node-role.kubernetes.io/storage
                      operator: In
                      values: ["true"]

        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            memory: 1Gi

      preservePoolsOnDelete: true # –ù–µ —É–¥–∞–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ CRD

    # StorageClass –¥–ª—è S3 buckets (—á–µ—Ä–µ–∑ Object Bucket Claims)
    storageClass:
      enabled: true
      name: ceph-bucket
      reclaimPolicy: Delete
      volumeBindingMode: Immediate
      parameters:
        region: us-east-1

# === Toolbox - –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥ (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø) ===
# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∫–æ–º–∞–Ω–¥: kubectl exec -n rook-ceph deploy/rook-ceph-tools -- ceph status
toolbox:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      memory: 1Gi
```

> üåê Dashboard - –ø–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–æ–ª—å

```bash
# –ü–æ–ª—É—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä–æ–ª—å
kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode && echo

# –õ–æ–≥–∏–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: admin
```

## –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Ingress

–°–æ–∑–¥–∞–π—Ç–µ Ingress –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ Dashboard —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä:

```yaml
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ceph-dashboard
  namespace: rook-ceph
  annotations:
    # –¢.–∫. backend —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç HTTPS (ssl: true –≤ –∫–æ–Ω—Ñ–∏–≥–µ), –Ω—É–∂–Ω–æ –ø—Ä–æ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ HTTPS
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    # –†–∞–∑—Ä–µ—à–∞–µ–º —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –æ—Ç Ceph
    nginx.ingress.kubernetes.io/proxy-ssl-verify: "false"
    # –í–∫–ª—é—á–∞–µ–º SSL —Ä–µ–¥–∏—Ä–µ–∫—Ç
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # Cert-manager –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ Let's Encrypt (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
    # cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx
  rules:
    - host: ceph.stroy-track.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: rook-ceph-mgr-dashboard
                port:
                  number: 8443
EOF
```

–¢–µ–ø–µ—Ä—å Dashboard –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: `https://ceph.stroy-track.local`

---

## –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –Ω–æ–¥—ã

1. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∏—Å–∫ –Ω–∞ –Ω–æ–≤–æ–π VPS (—Å–º. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Å–∫–æ–≤](#-–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–¥–∏—Å–∫–æ–≤-–Ω–∞-vps))
2. –û–±–Ω–æ–≤–∏—Ç–µ rook-ceph-cluster `values-cluster.yaml`, –¥–æ–±–∞–≤–∏–≤ –Ω–æ–≤—É—é –Ω–æ–¥—É –≤ —Å–µ–∫—Ü–∏—é `storage.nodes`
3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:

```bash
helm upgrade rook-ceph-cluster rook-release/rook-ceph-cluster \
  --namespace rook-ceph \
  --values values-cluster.yaml \
  --reuse-values
```

4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ OSD –∑–∞–ø—É—Å—Ç–∏–ª—Å—è:

```bash
kubectl get pods -n rook-ceph | grep osd
kubectl exec -n rook-ceph deploy/rook-ceph-tools -- ceph osd tree
```
